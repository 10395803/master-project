\contentsline {algorithm}{\numberline {1.1}{\ignorespaces Backbone of any supervised online learning algorithm; note that the full procedure ends when all training patterns yield an error which is below a defined threshold.\relax }}{13}{algorithm.1.1}
\contentsline {algorithm}{\numberline {1.2}{\ignorespaces Backbone of any supervised offline learning algorithm; the procedure to compute the accumulated error is provided as well.\relax }}{14}{algorithm.1.2}
\contentsline {algorithm}{\numberline {1.3}{\ignorespaces An iteration of the Levenberg-Marquardt training algorithm.\relax }}{19}{algorithm.1.3}
\contentsline {algorithm}{\numberline {1.4}{\ignorespaces The complete training algorithm adopted in our numerical tests.\relax }}{22}{algorithm.1.4}
\contentsline {algorithm}{\numberline {2.1}{\ignorespaces The Newton's method applied to the nonlinear system \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:galerkin-nonlinear-system}\unskip \@@italiccorr )}}.\relax }}{41}{algorithm.2.1}
\contentsline {algorithm}{\numberline {2.2}{\ignorespaces The Newton's method applied to the reduced nonlinear system \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:rb-nonlinear-system}\unskip \@@italiccorr )}}.\relax }}{48}{algorithm.2.2}
\contentsline {algorithm}{\numberline {2.3}{\ignorespaces The POD algorithm.\relax }}{52}{algorithm.2.3}
\contentsline {algorithm}{\numberline {2.4}{\ignorespaces The offline and online stages for the POD-Galerkin (POD-G) RB method.\relax }}{53}{algorithm.2.4}
\contentsline {algorithm}{\numberline {2.5}{\ignorespaces The offline and online stages for the POD-NN RB method.\relax }}{61}{algorithm.2.5}
\contentsline {algorithm}{\numberline {2.6}{\ignorespaces Selection of an optimal network configuration.\relax }}{64}{algorithm.2.6}
